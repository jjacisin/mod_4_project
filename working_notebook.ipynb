{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_idx</th>\n",
       "      <th>img_file</th>\n",
       "      <th>img_link</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>761183272</td>\n",
       "      <td>0761183272.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/61Y5cOdH...</td>\n",
       "      <td>Mom's Family Wall Calendar 2016</td>\n",
       "      <td>Sandra Boynton</td>\n",
       "      <td>3</td>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1623439671</td>\n",
       "      <td>1623439671.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/61t-hrSw...</td>\n",
       "      <td>Doug the Pug 2016 Wall Calendar</td>\n",
       "      <td>Doug the Pug</td>\n",
       "      <td>3</td>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00O80WC6I</td>\n",
       "      <td>B00O80WC6I.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41X-KQqs...</td>\n",
       "      <td>Moleskine 2016 Weekly Notebook, 12M, Large, Bl...</td>\n",
       "      <td>Moleskine</td>\n",
       "      <td>3</td>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>761182187</td>\n",
       "      <td>0761182187.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/61j-4gxJ...</td>\n",
       "      <td>365 Cats Color Page-A-Day Calendar 2016</td>\n",
       "      <td>Workman Publishing</td>\n",
       "      <td>3</td>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1578052084</td>\n",
       "      <td>1578052084.jpg</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51Ry4Tsq...</td>\n",
       "      <td>Sierra Club Engagement Calendar 2016</td>\n",
       "      <td>Sierra Club</td>\n",
       "      <td>3</td>\n",
       "      <td>Calendars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      img_idx        img_file  \\\n",
       "0   761183272  0761183272.jpg   \n",
       "1  1623439671  1623439671.jpg   \n",
       "2  B00O80WC6I  B00O80WC6I.jpg   \n",
       "3   761182187  0761182187.jpg   \n",
       "4  1578052084  1578052084.jpg   \n",
       "\n",
       "                                            img_link  \\\n",
       "0  http://ecx.images-amazon.com/images/I/61Y5cOdH...   \n",
       "1  http://ecx.images-amazon.com/images/I/61t-hrSw...   \n",
       "2  http://ecx.images-amazon.com/images/I/41X-KQqs...   \n",
       "3  http://ecx.images-amazon.com/images/I/61j-4gxJ...   \n",
       "4  http://ecx.images-amazon.com/images/I/51Ry4Tsq...   \n",
       "\n",
       "                                               title              author  \\\n",
       "0                    Mom's Family Wall Calendar 2016      Sandra Boynton   \n",
       "1                    Doug the Pug 2016 Wall Calendar        Doug the Pug   \n",
       "2  Moleskine 2016 Weekly Notebook, 12M, Large, Bl...           Moleskine   \n",
       "3            365 Cats Color Page-A-Day Calendar 2016  Workman Publishing   \n",
       "4               Sierra Club Engagement Calendar 2016         Sierra Club   \n",
       "\n",
       "   cat_id   category  \n",
       "0       3  Calendars  \n",
       "1       3  Calendars  \n",
       "2       3  Calendars  \n",
       "3       3  Calendars  \n",
       "4       3  Calendars  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create dataframe\n",
    "df = pd.read_csv('books.csv',encoding=\"latin\",header=None)\n",
    "df.columns = ['img_idx','img_file','img_link','title','author','cat_id','category']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Calendars', 'Comics & Graphic Novels', 'Test Preparation',\n",
       "       'Mystery, Thriller & Suspense', 'Science Fiction & Fantasy',\n",
       "       'Romance', 'Humor & Entertainment', 'Literature & Fiction',\n",
       "       'Gay & Lesbian', 'Engineering & Transportation',\n",
       "       'Cookbooks, Food & Wine', 'Crafts, Hobbies & Home',\n",
       "       'Arts & Photography', 'Education & Teaching',\n",
       "       'Parenting & Relationships', 'Self-Help', 'Computers & Technology',\n",
       "       'Medical Books', 'Science & Math', 'Health, Fitness & Dieting',\n",
       "       'Business & Money', 'Law', 'Biographies & Memoirs', 'History',\n",
       "       'Politics & Social Sciences', 'Reference',\n",
       "       'Christian Books & Bibles', 'Religion & Spirituality',\n",
       "       'Sports & Outdoors', 'Teen & Young Adult', \"Children's Books\",\n",
       "       'Travel'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What are our categories?\n",
    "df.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cleaner\n",
    "cleaner.build_images_parallel(df, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index     img_idx        img_file  \\\n",
      "0  110861   989167615  0989167615.jpg   \n",
      "1   59141  1565238133  1565238133.jpg   \n",
      "2  148860   849947227  0849947227.jpg   \n",
      "3  195203  009174153X  009174153X.jpg   \n",
      "4    5678  1455703338  1455703338.jpg   \n",
      "\n",
      "                                            img_link  \\\n",
      "0  http://ecx.images-amazon.com/images/I/51X3DJhC...   \n",
      "1  http://ecx.images-amazon.com/images/I/51n%2BQZ...   \n",
      "2  http://ecx.images-amazon.com/images/I/41jz2Snm...   \n",
      "3  http://ecx.images-amazon.com/images/I/51csIjCf...   \n",
      "4  http://ecx.images-amazon.com/images/I/51MRO9gG...   \n",
      "\n",
      "                                               title  \\\n",
      "0  A Just Cause: A True Story of Courage, Hope, &...   \n",
      "1  Great Book of Tattoo Designs, Revised Edition:...   \n",
      "2  Grieving God's Way: The Path to Lasting Hope a...   \n",
      "3  The Wilder Shores of Marx: Journeys in a Vanis...   \n",
      "4               Admission Assessment Exam Review, 3e   \n",
      "\n",
      "                     author  cat_id                  category  \n",
      "0  James H. Holzrichter Sr.       2          Business & Money  \n",
      "1                Lora Irish       0        Arts & Photography  \n",
      "2         Margaret Brownley       9  Christian Books & Bibles  \n",
      "3           Anthony Daniels      29                    Travel  \n",
      "4                      HESI      28          Test Preparation  \n"
     ]
    }
   ],
   "source": [
    "#test train split the dataframe\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Notice that we don't drop target from x_train, since we have to feed a dataframe with target\n",
    "# to train_generator\n",
    "\n",
    "target = df['category']\n",
    "x_train, x_test, y_train, y_test = train_test_split(df, target, test_size=0.2)\n",
    "\n",
    "\n",
    "#have to reset index of x_test so that can use image_data_generator on it ??\n",
    "x_test = x_test.reset_index()\n",
    "y_test = y_test.reset_index()\n",
    "print(x_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 154543 images belonging to 32 classes.\n",
      "Found 38592 images belonging to 32 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "directory = 'pictures/'\n",
    "batch_size = 32\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_dataframe(x_train, directory, x_col='img_file', y_col='category', has_ext=True, target_size=(256, 256), color_mode='rgb', classes=None, class_mode='categorical', batch_size=batch_size, shuffle=True, seed=None, save_to_dir=None, save_prefix='', save_format='jpeg', subset=None, interpolation='nearest')\n",
    "#train_images, train_labels = next(train_generator)\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_dataframe(x_test, directory, x_col='img_file', y_col='category', has_ext=True, target_size=(256, 256), color_mode='rgb', classes=None, class_mode='categorical', batch_size=batch_size, shuffle=True, seed=None, save_to_dir=None, save_prefix='', save_format='jpeg', subset=None, interpolation='nearest')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do not reshape\n",
    "\n",
    "#print('Before: ', train_images.shape)\n",
    "#train_images = train_images.reshape(train_images.shape[0], -1)\n",
    "#print('After: ', train_images.shape)\n",
    "# That's a lot of input neurons!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(df.category.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from keras.applications import MobileNet\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import inception_v3\n",
    "\n",
    "base_model=inception_v3.InceptionV3(weights='imagenet',include_top=False)\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# fully-connected layer with 1024 neurons \n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "# this is the model we will train\n",
    "model = Model(input=base_model.input, output=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "activation_1\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "activation_2\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "activation_3\n",
      "max_pooling2d_1\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "activation_4\n",
      "conv2d_5\n",
      "batch_normalization_5\n",
      "activation_5\n",
      "max_pooling2d_2\n",
      "conv2d_9\n",
      "batch_normalization_9\n",
      "activation_9\n",
      "conv2d_7\n",
      "conv2d_10\n",
      "batch_normalization_7\n",
      "batch_normalization_10\n",
      "activation_7\n",
      "activation_10\n",
      "average_pooling2d_1\n",
      "conv2d_6\n",
      "conv2d_8\n",
      "conv2d_11\n",
      "conv2d_12\n",
      "batch_normalization_6\n",
      "batch_normalization_8\n",
      "batch_normalization_11\n",
      "batch_normalization_12\n",
      "activation_6\n",
      "activation_8\n",
      "activation_11\n",
      "activation_12\n",
      "mixed0\n",
      "conv2d_16\n",
      "batch_normalization_16\n",
      "activation_16\n",
      "conv2d_14\n",
      "conv2d_17\n",
      "batch_normalization_14\n",
      "batch_normalization_17\n",
      "activation_14\n",
      "activation_17\n",
      "average_pooling2d_2\n",
      "conv2d_13\n",
      "conv2d_15\n",
      "conv2d_18\n",
      "conv2d_19\n",
      "batch_normalization_13\n",
      "batch_normalization_15\n",
      "batch_normalization_18\n",
      "batch_normalization_19\n",
      "activation_13\n",
      "activation_15\n",
      "activation_18\n",
      "activation_19\n",
      "mixed1\n",
      "conv2d_23\n",
      "batch_normalization_23\n",
      "activation_23\n",
      "conv2d_21\n",
      "conv2d_24\n",
      "batch_normalization_21\n",
      "batch_normalization_24\n",
      "activation_21\n",
      "activation_24\n",
      "average_pooling2d_3\n",
      "conv2d_20\n",
      "conv2d_22\n",
      "conv2d_25\n",
      "conv2d_26\n",
      "batch_normalization_20\n",
      "batch_normalization_22\n",
      "batch_normalization_25\n",
      "batch_normalization_26\n",
      "activation_20\n",
      "activation_22\n",
      "activation_25\n",
      "activation_26\n",
      "mixed2\n",
      "conv2d_28\n",
      "batch_normalization_28\n",
      "activation_28\n",
      "conv2d_29\n",
      "batch_normalization_29\n",
      "activation_29\n",
      "conv2d_27\n",
      "conv2d_30\n",
      "batch_normalization_27\n",
      "batch_normalization_30\n",
      "activation_27\n",
      "activation_30\n",
      "max_pooling2d_3\n",
      "mixed3\n",
      "conv2d_35\n",
      "batch_normalization_35\n",
      "activation_35\n",
      "conv2d_36\n",
      "batch_normalization_36\n",
      "activation_36\n",
      "conv2d_32\n",
      "conv2d_37\n",
      "batch_normalization_32\n",
      "batch_normalization_37\n",
      "activation_32\n",
      "activation_37\n",
      "conv2d_33\n",
      "conv2d_38\n",
      "batch_normalization_33\n",
      "batch_normalization_38\n",
      "activation_33\n",
      "activation_38\n",
      "average_pooling2d_4\n",
      "conv2d_31\n",
      "conv2d_34\n",
      "conv2d_39\n",
      "conv2d_40\n",
      "batch_normalization_31\n",
      "batch_normalization_34\n",
      "batch_normalization_39\n",
      "batch_normalization_40\n",
      "activation_31\n",
      "activation_34\n",
      "activation_39\n",
      "activation_40\n",
      "mixed4\n",
      "conv2d_45\n",
      "batch_normalization_45\n",
      "activation_45\n",
      "conv2d_46\n",
      "batch_normalization_46\n",
      "activation_46\n",
      "conv2d_42\n",
      "conv2d_47\n",
      "batch_normalization_42\n",
      "batch_normalization_47\n",
      "activation_42\n",
      "activation_47\n",
      "conv2d_43\n",
      "conv2d_48\n",
      "batch_normalization_43\n",
      "batch_normalization_48\n",
      "activation_43\n",
      "activation_48\n",
      "average_pooling2d_5\n",
      "conv2d_41\n",
      "conv2d_44\n",
      "conv2d_49\n",
      "conv2d_50\n",
      "batch_normalization_41\n",
      "batch_normalization_44\n",
      "batch_normalization_49\n",
      "batch_normalization_50\n",
      "activation_41\n",
      "activation_44\n",
      "activation_49\n",
      "activation_50\n",
      "mixed5\n",
      "conv2d_55\n",
      "batch_normalization_55\n",
      "activation_55\n",
      "conv2d_56\n",
      "batch_normalization_56\n",
      "activation_56\n",
      "conv2d_52\n",
      "conv2d_57\n",
      "batch_normalization_52\n",
      "batch_normalization_57\n",
      "activation_52\n",
      "activation_57\n",
      "conv2d_53\n",
      "conv2d_58\n",
      "batch_normalization_53\n",
      "batch_normalization_58\n",
      "activation_53\n",
      "activation_58\n",
      "average_pooling2d_6\n",
      "conv2d_51\n",
      "conv2d_54\n",
      "conv2d_59\n",
      "conv2d_60\n",
      "batch_normalization_51\n",
      "batch_normalization_54\n",
      "batch_normalization_59\n",
      "batch_normalization_60\n",
      "activation_51\n",
      "activation_54\n",
      "activation_59\n",
      "activation_60\n",
      "mixed6\n",
      "conv2d_65\n",
      "batch_normalization_65\n",
      "activation_65\n",
      "conv2d_66\n",
      "batch_normalization_66\n",
      "activation_66\n",
      "conv2d_62\n",
      "conv2d_67\n",
      "batch_normalization_62\n",
      "batch_normalization_67\n",
      "activation_62\n",
      "activation_67\n",
      "conv2d_63\n",
      "conv2d_68\n",
      "batch_normalization_63\n",
      "batch_normalization_68\n",
      "activation_63\n",
      "activation_68\n",
      "average_pooling2d_7\n",
      "conv2d_61\n",
      "conv2d_64\n",
      "conv2d_69\n",
      "conv2d_70\n",
      "batch_normalization_61\n",
      "batch_normalization_64\n",
      "batch_normalization_69\n",
      "batch_normalization_70\n",
      "activation_61\n",
      "activation_64\n",
      "activation_69\n",
      "activation_70\n",
      "mixed7\n",
      "conv2d_73\n",
      "batch_normalization_73\n",
      "activation_73\n",
      "conv2d_74\n",
      "batch_normalization_74\n",
      "activation_74\n",
      "conv2d_71\n",
      "conv2d_75\n",
      "batch_normalization_71\n",
      "batch_normalization_75\n",
      "activation_71\n",
      "activation_75\n",
      "conv2d_72\n",
      "conv2d_76\n",
      "batch_normalization_72\n",
      "batch_normalization_76\n",
      "activation_72\n",
      "activation_76\n",
      "max_pooling2d_4\n",
      "mixed8\n",
      "conv2d_81\n",
      "batch_normalization_81\n",
      "activation_81\n",
      "conv2d_78\n",
      "conv2d_82\n",
      "batch_normalization_78\n",
      "batch_normalization_82\n",
      "activation_78\n",
      "activation_82\n",
      "conv2d_79\n",
      "conv2d_80\n",
      "conv2d_83\n",
      "conv2d_84\n",
      "average_pooling2d_8\n",
      "conv2d_77\n",
      "batch_normalization_79\n",
      "batch_normalization_80\n",
      "batch_normalization_83\n",
      "batch_normalization_84\n",
      "conv2d_85\n",
      "batch_normalization_77\n",
      "activation_79\n",
      "activation_80\n",
      "activation_83\n",
      "activation_84\n",
      "batch_normalization_85\n",
      "activation_77\n",
      "mixed9_0\n",
      "concatenate_1\n",
      "activation_85\n",
      "mixed9\n",
      "conv2d_90\n",
      "batch_normalization_90\n",
      "activation_90\n",
      "conv2d_87\n",
      "conv2d_91\n",
      "batch_normalization_87\n",
      "batch_normalization_91\n",
      "activation_87\n",
      "activation_91\n",
      "conv2d_88\n",
      "conv2d_89\n",
      "conv2d_92\n",
      "conv2d_93\n",
      "average_pooling2d_9\n",
      "conv2d_86\n",
      "batch_normalization_88\n",
      "batch_normalization_89\n",
      "batch_normalization_92\n",
      "batch_normalization_93\n",
      "conv2d_94\n",
      "batch_normalization_86\n",
      "activation_88\n",
      "activation_89\n",
      "activation_92\n",
      "activation_93\n",
      "batch_normalization_94\n",
      "activation_86\n",
      "mixed9_1\n",
      "concatenate_2\n",
      "activation_94\n",
      "mixed10\n",
      "global_average_pooling2d_1\n",
      "dense_1\n",
      "dense_2\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "  15/5189 [..............................] - ETA: 25:18:08 - loss: 0.1520 - acc: 0.9667"
     ]
    }
   ],
   "source": [
    "#train this biiiitch\n",
    "EPOCHS = 1\n",
    "\n",
    "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# need to fit by generator since data won't fit into memory!\n",
    "#model.fit(x_train,\n",
    "#          y_train,\n",
    "#          epochs=10,\n",
    "#          batch_size=32,\n",
    "#          validation_data=(x_test, y_test))\n",
    "\n",
    "model.fit_generator(train_generator, validation_data=test_generator, \n",
    "                    steps_per_epoch=len(x_train)//batch_size, \n",
    "                    validation_steps=len(x_test)//batch_size, epochs=EPOCHS)\n",
    "\n",
    "#ok\n",
    "#ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: get live training vs validation loss graph... and speed this up somehow! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
